{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "from fjd_metric import FJDMetric\n",
    "from embeddings import OneHotEmbedding, InceptionEmbedding\n",
    "from torchvision.models.inception import inception_v3\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from scipy.stats import entropy\n",
    "from msssim import MultiScaleSSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "\n",
    "class oldNetG(nn.Module):\n",
    "    def __init__(self, lenz):\n",
    "        super(oldNetG, self).__init__()\n",
    "        self.lenz = lenz\n",
    "        self.l = nn.Linear(110,384)\n",
    "\n",
    "        self.t1 = nn.ConvTranspose2d(384, 192, 6, (2,2))\n",
    "        self.bn1 = nn.BatchNorm2d(192)\n",
    "        self.t2 = nn.ConvTranspose2d(192, 96, 5, (2, 2))\n",
    "        self.bn2 = nn.BatchNorm2d(96)\n",
    "        \n",
    "        self.t3 = nn.ConvTranspose2d(96, 3, 4, (2, 2))\n",
    "        \n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "#         print(x.shape)\n",
    "        x = x.view(-1, self.lenz)\n",
    "#         print(x.shape)\n",
    "        x = self.l(x).view(-1, 384, 1, 1)\n",
    "#         print(x.shape)\n",
    "        x = F.relu(self.bn1(self.t1(x)))\n",
    "#         print(x.shape)\n",
    "        x = F.relu(self.bn2(self.t2(x)))\n",
    "#         print(x.shape)\n",
    "        x = F.tanh(self.t3(x))\n",
    "#         print(x.shape)\n",
    "        return x\n",
    "\n",
    "class GANWrapper:\n",
    "    def __init__(self, model, model_checkpoint=None):\n",
    "        self.model = model\n",
    "\n",
    "        if model_checkpoint is not None:\n",
    "            self.model_checkpoint = model_checkpoint\n",
    "            self.load_model()\n",
    "\n",
    "    def load_model(self):\n",
    "        # self.model.eval()  # uncomment to put in eval mode if desired\n",
    "        self.model = self.model.cuda()\n",
    "\n",
    "        state_dict = torch.load(self.model_checkpoint)\n",
    "        self.model.load_state_dict(state_dict)\n",
    "\n",
    "    def get_noise(self, batch_size):\n",
    "        # change the noise dimension as required\n",
    "        z = torch.cuda.FloatTensor(batch_size, 128).normal_()\n",
    "        return z\n",
    "\n",
    "    def __call__(self, y):\n",
    "#         print(y)\n",
    "#         print(type(y))\n",
    "#         print(y.shape)\n",
    "#         y.unsqueeze(1)\n",
    "        np_gen_label = y.cpu().numpy()\n",
    "        batch_size = y.size(0)\n",
    "#         z = self.get_noise(batch_size)\n",
    "#         samples = self.model(z, y)\n",
    "        \n",
    "    \n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        onehot = np.zeros((batch_size, 10))\n",
    "        onehot[np.arange(batch_size), np_gen_label] = 1\n",
    "        z = np.concatenate((noise, onehot), axis=1)\n",
    "        z = torch.from_numpy(z).float().to('cuda')\n",
    "\n",
    "\n",
    "        gen_imgs = self.model(z)\n",
    "        return gen_imgs\n",
    "    \n",
    "class newNetG(nn.Module):\n",
    "    def __init__(self, lenz):\n",
    "        super(newNetG, self).__init__()\n",
    "        self.lenz = lenz\n",
    "        self.l = nn.Linear(110,512)\n",
    "\n",
    "        self.t1 = nn.ConvTranspose2d(512, 384, 4, (2,2),1)\n",
    "        self.bn1 = nn.BatchNorm2d(384)\n",
    "        self.t2 = nn.ConvTranspose2d(384, 192, 4, (2, 2),1)\n",
    "        self.bn2 = nn.BatchNorm2d(192)\n",
    "        self.t3 = nn.ConvTranspose2d(192, 148, 4, (2, 2),1)\n",
    "        self.bn3 = nn.BatchNorm2d(148)\n",
    "        self.t4 = nn.ConvTranspose2d(148, 92, 4, (2, 2),1)\n",
    "        \n",
    "        self.bn4 = nn.BatchNorm2d(92)\n",
    "        self.t5 = nn.ConvTranspose2d(92, 3, 4, (2, 2),1)\n",
    "        \n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "#         print(x.shape)\n",
    "        x = x.view(-1, self.lenz)\n",
    "#         print(x.shape)\n",
    "        x = self.l(x).view(-1, 512, 1, 1)\n",
    "#         print(x.shape)\n",
    "        x = F.relu(self.bn1(self.t1(x)))\n",
    "#         print(x.shape)\n",
    "        x = F.relu(self.bn2(self.t2(x)))\n",
    "#         print(x.shape)\n",
    "        x = F.relu(self.bn3(self.t3(x)))\n",
    "        x = F.relu(self.bn4(self.t4(x)))\n",
    "#         print(x.shape)\n",
    "        x = F.tanh(self.t5(x))\n",
    "#         print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=0)\n",
    "\n",
    "inception_embedding = InceptionEmbedding(parallel=False)\n",
    "onehot_embedding = OneHotEmbedding(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reference statistics from datasets/cifar_train_stats.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution:   0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "Computing generated distribution: 100%|██████████| 100/100 [00:16<00:00,  5.94it/s]\n",
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  485.62789502169403\n",
      "FJD:  487.88277249131124\n",
      "tensor(21.7352, device='cuda:0', dtype=torch.float64)\n",
      "Loading reference statistics from datasets/cifar_train_stats.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.77it/s]\n",
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  86.92183322781841\n",
      "FJD:  100.28399270743967\n",
      "tensor(21.7352, device='cuda:0', dtype=torch.float64)\n",
      "Loading reference statistics from datasets/cifar_train_stats.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.82it/s]\n",
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  82.6511854205275\n",
      "FJD:  95.07041197309036\n",
      "tensor(21.7352, device='cuda:0', dtype=torch.float64)\n",
      "Loading reference statistics from datasets/cifar_train_stats.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.76it/s]\n",
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  79.37391519366861\n",
      "FJD:  91.66352567546346\n",
      "tensor(21.7352, device='cuda:0', dtype=torch.float64)\n",
      "Loading reference statistics from datasets/cifar_train_stats.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.73it/s]\n",
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  78.55823796639191\n",
      "FJD:  88.22626166489476\n",
      "tensor(21.7352, device='cuda:0', dtype=torch.float64)\n",
      "Loading reference statistics from datasets/cifar_train_stats.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.61it/s]\n",
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.78it/s]\n",
      "Computing generated distribution:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  80.16680078565037\n",
      "FJD:  90.23355326517867\n",
      "tensor(21.7352, device='cuda:0', dtype=torch.float64)\n",
      "Loading reference statistics from datasets/cifar_train_stats.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.82it/s]\n",
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  69.98073857340347\n",
      "FJD:  79.9778990042987\n",
      "tensor(21.7352, device='cuda:0', dtype=torch.float64)\n",
      "Loading reference statistics from datasets/cifar_train_stats.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.79it/s]\n",
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  68.75876184948407\n",
      "FJD:  78.2382495143363\n",
      "tensor(21.7352, device='cuda:0', dtype=torch.float64)\n",
      "Loading reference statistics from datasets/cifar_train_stats.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.70it/s]\n",
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  70.1439803882796\n",
      "FJD:  78.18880871299757\n",
      "tensor(21.7352, device='cuda:0', dtype=torch.float64)\n",
      "Loading reference statistics from datasets/cifar_train_stats.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.73it/s]\n",
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  67.7486926299519\n",
      "FJD:  76.51653078745812\n",
      "tensor(21.7352, device='cuda:0', dtype=torch.float64)\n",
      "Loading reference statistics from datasets/cifar_train_stats.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.68it/s]\n",
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  68.01113164618539\n",
      "FJD:  77.16531961736177\n",
      "tensor(21.7352, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "fjds = []\n",
    "fids = []\n",
    "for epoch in range(0,550,50):\n",
    "    epoch = str(epoch)\n",
    "    net_g = oldNetG(110).to('cuda')\n",
    "    PATH = 'original_model/models/netG_epoch_'+epoch+'.pth'\n",
    "\n",
    "    net_g.load_state_dict(torch.load(PATH))\n",
    "    net_g.eval()\n",
    "\n",
    "    gan = GANWrapper(net_g)\n",
    "    fjd_metric = FJDMetric(gan=gan,\n",
    "                           reference_loader=trainloader,\n",
    "                           condition_loader=testloader,\n",
    "                           image_embedding=inception_embedding,\n",
    "                           condition_embedding=onehot_embedding,\n",
    "                           reference_stats_path='datasets/cifar_train_stats.npz',\n",
    "                           save_reference_stats=True,\n",
    "                           samples_per_condition=1,\n",
    "                           cuda=True)\n",
    "\n",
    "    fid = fjd_metric.get_fid()\n",
    "    fjd = fjd_metric.get_fjd()\n",
    "    print('FID: ', fid)\n",
    "    print('FJD: ', fjd)\n",
    "    print(fjd_metric.alpha)\n",
    "    fids.append(fid)\n",
    "    fjds.append(fjd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reference statistics from datasets/cifar_train_stats.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.83it/s]\n",
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  483.2364051485665\n",
      "FJD:  484.77989003480866\n",
      "Loading reference statistics from datasets/cifar_train_stats.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.72it/s]\n",
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  130.58560001574222\n",
      "FJD:  160.23102420293435\n",
      "Loading reference statistics from datasets/cifar_train_stats.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.58it/s]\n",
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  123.3490309028249\n",
      "FJD:  154.12803149100864\n",
      "Loading reference statistics from datasets/cifar_train_stats.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.64it/s]\n",
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  114.30469661685078\n",
      "FJD:  141.67969992260896\n",
      "Loading reference statistics from datasets/cifar_train_stats.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.56it/s]\n",
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  114.80089643373623\n",
      "FJD:  145.568975978141\n",
      "Loading reference statistics from datasets/cifar_train_stats.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.61it/s]\n",
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  113.78075578669407\n",
      "FJD:  146.2069855187417\n",
      "Loading reference statistics from datasets/cifar_train_stats.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.61it/s]\n",
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  123.48969677493272\n",
      "FJD:  160.7689515382424\n",
      "Loading reference statistics from datasets/cifar_train_stats.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution: 100%|██████████| 100/100 [00:18<00:00,  5.52it/s]\n",
      "Computing generated distribution: 100%|██████████| 100/100 [00:18<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  121.10538853611044\n",
      "FJD:  154.81216104988653\n",
      "Loading reference statistics from datasets/cifar_train_stats.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution: 100%|██████████| 100/100 [00:18<00:00,  5.48it/s]\n",
      "Computing generated distribution: 100%|██████████| 100/100 [00:18<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  147.72691906471675\n",
      "FJD:  181.44155527631415\n",
      "Loading reference statistics from datasets/cifar_train_stats.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution: 100%|██████████| 100/100 [00:18<00:00,  5.49it/s]\n",
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  155.24264264852695\n",
      "FJD:  196.09805606794134\n",
      "Loading reference statistics from datasets/cifar_train_stats.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution: 100%|██████████| 100/100 [00:17<00:00,  5.56it/s]\n",
      "Computing generated distribution: 100%|██████████| 100/100 [00:18<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID:  125.96540365597787\n",
      "FJD:  166.96340534691535\n"
     ]
    }
   ],
   "source": [
    "new_fjds = []\n",
    "new_fids = []\n",
    "for epoch in range(0,550,50):\n",
    "    epoch = str(epoch)\n",
    "    net_g = newNetG(110).to('cuda')\n",
    "    PATH = 'new_model/models/netG_epoch_'+epoch+'.pth'\n",
    "\n",
    "    net_g.load_state_dict(torch.load(PATH))\n",
    "    net_g.eval()\n",
    "\n",
    "    gan = GANWrapper(net_g)\n",
    "    fjd_metric = FJDMetric(gan=gan,\n",
    "                           reference_loader=trainloader,\n",
    "                           condition_loader=testloader,\n",
    "                           image_embedding=inception_embedding,\n",
    "                           condition_embedding=onehot_embedding,\n",
    "                           reference_stats_path='datasets/cifar_train_stats.npz',\n",
    "                           save_reference_stats=True,\n",
    "                           samples_per_condition=1,\n",
    "                           cuda=True)\n",
    "\n",
    "    fid = fjd_metric.get_fid()\n",
    "    fjd = fjd_metric.get_fjd()\n",
    "    print('FID: ', fid)\n",
    "    print('FJD: ', fjd)\n",
    "    new_fids.append(fid)\n",
    "    new_fjds.append(fjd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_score(imgs, cuda=True, batch_size=32, resize=False, splits=1):\n",
    "    \"\"\"Computes the inception score of the generated images imgs\n",
    "    imgs -- Torch dataset of (3xHxW) numpy images normalized in the range [-1, 1]\n",
    "    cuda -- whether or not to run on GPU\n",
    "    batch_size -- batch size for feeding into Inception v3\n",
    "    splits -- number of splits\n",
    "    \"\"\"\n",
    "    N = len(imgs)\n",
    "\n",
    "    assert batch_size > 0\n",
    "    assert N > batch_size\n",
    "\n",
    "    # Set up dtype\n",
    "    if cuda:\n",
    "        dtype = torch.cuda.FloatTensor\n",
    "    else:\n",
    "        if torch.cuda.is_available():\n",
    "            print(\"WARNING: You have a CUDA device, so you should probably set cuda=True\")\n",
    "        dtype = torch.FloatTensor\n",
    "\n",
    "    # Set up dataloader\n",
    "    dataloader = torch.utils.data.DataLoader(imgs, batch_size=batch_size)\n",
    "\n",
    "    # Load inception model\n",
    "    inception_model = inception_v3(pretrained=True, transform_input=False).type(dtype)\n",
    "    inception_model.eval();\n",
    "    up = nn.Upsample(size=(299, 299), mode='bilinear').type(dtype)\n",
    "    def get_pred(x, resize_1):\n",
    "\n",
    "        if resize_1:\n",
    "            x = up(x)\n",
    "\n",
    "        x = inception_model(x)\n",
    "        return F.softmax(x).data.cpu().numpy()\n",
    "\n",
    "    # Get predictions\n",
    "    preds = np.zeros((N, 1000))\n",
    "\n",
    "    for i, batch in enumerate(dataloader, 0):\n",
    "        batch = batch.type(dtype)\n",
    "        batchv = Variable(batch)\n",
    "        batch_size_i = batch.size()[0]\n",
    "\n",
    "        preds[i*batch_size:i*batch_size + batch_size_i] = get_pred(batchv, resize)\n",
    "\n",
    "    # Now compute the mean kl-div\n",
    "    split_scores = []\n",
    "\n",
    "    for k in range(splits):\n",
    "        part = preds[k * (N // splits): (k+1) * (N // splits), :]\n",
    "        py = np.mean(part, axis=0)\n",
    "        scores = []\n",
    "        for i in range(part.shape[0]):\n",
    "            pyx = part[i, :]\n",
    "            scores.append(entropy(pyx, py))\n",
    "        split_scores.append(np.exp(np.mean(scores)))\n",
    "\n",
    "    return np.mean(split_scores), np.std(split_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0707358432321514, 0.0)\n",
      "(2.6277085355430523, 0.0)\n",
      "(3.062116927683054, 0.0)\n",
      "(2.981237645431223, 0.0)\n",
      "(3.5163301157166953, 0.0)\n",
      "(3.286465983775069, 0.0)\n",
      "(3.4853269111524883, 0.0)\n",
      "(3.4182588323310035, 0.0)\n",
      "(3.526760380834381, 0.0)\n",
      "(3.600546285805776, 0.0)\n",
      "(3.422761106399059, 0.0)\n"
     ]
    }
   ],
   "source": [
    "isss = []\n",
    "for epoch in range(0,550,50):\n",
    "    epoch = str(epoch)\n",
    "    net_g = oldNetG(110).to('cuda')\n",
    "    PATH = 'models/netG_epoch_'+epoch+'.pth'\n",
    "\n",
    "    net_g.load_state_dict(torch.load(PATH))\n",
    "    net_g.eval()\n",
    "\n",
    "\n",
    "\n",
    "    batch_size = 500\n",
    "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "    np_gen_label = np.random.randint(0, 10, batch_size)\n",
    "    onehot = np.zeros((batch_size, 10))\n",
    "    onehot[np.arange(batch_size), np_gen_label] = 1\n",
    "    z = np.concatenate((noise, onehot), axis=1)\n",
    "    z = torch.from_numpy(z).float().to('cuda')\n",
    "\n",
    "\n",
    "    gen_imgs = net_g(z)\n",
    "    iss = inception_score(gen_imgs,resize = True)\n",
    "    print(iss)\n",
    "    isss.append(iss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0361979844563123, 0.0)\n",
      "(3.1250639132742104, 0.0)\n",
      "(2.6706251168500152, 0.0)\n",
      "(3.2054184668702494, 0.0)\n",
      "(3.0327701959704916, 0.0)\n",
      "(2.835451290012061, 0.0)\n",
      "(3.0152388156052834, 0.0)\n",
      "(3.0543817028837155, 0.0)\n",
      "(3.2982044649736846, 0.0)\n",
      "(3.2207540985145253, 0.0)\n",
      "(3.1392144695467854, 0.0)\n"
     ]
    }
   ],
   "source": [
    "newisss = []\n",
    "for epoch in range(0,550,50):\n",
    "    epoch = str(epoch)\n",
    "    net_g = newNetG(110).to('cuda')\n",
    "    PATH = 'new_model/models/netG_epoch_'+epoch+'.pth'\n",
    "\n",
    "    net_g.load_state_dict(torch.load(PATH))\n",
    "    net_g.eval()\n",
    "\n",
    "\n",
    "\n",
    "    batch_size = 500\n",
    "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "    np_gen_label = np.random.randint(0, 10, batch_size)\n",
    "    onehot = np.zeros((batch_size, 10))\n",
    "    onehot[np.arange(batch_size), np_gen_label] = 1\n",
    "    z = np.concatenate((noise, onehot), axis=1)\n",
    "    z = torch.from_numpy(z).float().to('cuda')\n",
    "\n",
    "\n",
    "    gen_imgs = net_g(z)\n",
    "    iss = inception_score(gen_imgs,resize = True)\n",
    "    print(iss)\n",
    "    newisss.append(iss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.4297642099890937, 0.0)\n"
     ]
    }
   ],
   "source": [
    "class _netG_CIFAR10(nn.Module):\n",
    "    def __init__(self, ngpu, nz):\n",
    "        super(_netG_CIFAR10, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.nz = nz\n",
    "\n",
    "        # first linear layer\n",
    "        self.fc1 = nn.Linear(110, 384)\n",
    "        # Transposed Convolution 2\n",
    "        self.tconv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(384, 192, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        # Transposed Convolution 3\n",
    "        self.tconv3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(192, 96, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        # Transposed Convolution 4\n",
    "        self.tconv4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(96, 48, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        # Transposed Convolution 4\n",
    "        self.tconv5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(48, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            input = input.view(-1, self.nz)\n",
    "            fc1 = nn.parallel.data_parallel(self.fc1, input, range(self.ngpu))\n",
    "            fc1 = fc1.view(-1, 384, 1, 1)\n",
    "            tconv2 = nn.parallel.data_parallel(self.tconv2, fc1, range(self.ngpu))\n",
    "            tconv3 = nn.parallel.data_parallel(self.tconv3, tconv2, range(self.ngpu))\n",
    "            tconv4 = nn.parallel.data_parallel(self.tconv4, tconv3, range(self.ngpu))\n",
    "            tconv5 = nn.parallel.data_parallel(self.tconv5, tconv4, range(self.ngpu))\n",
    "            output = tconv5\n",
    "        else:\n",
    "            input = input.view(-1, self.nz)\n",
    "            fc1 = self.fc1(input)\n",
    "            fc1 = fc1.view(-1, 384, 1, 1)\n",
    "            tconv2 = self.tconv2(fc1)\n",
    "            tconv3 = self.tconv3(tconv2)\n",
    "            tconv4 = self.tconv4(tconv3)\n",
    "            tconv5 = self.tconv5(tconv4)\n",
    "            output = tconv5\n",
    "        return output\n",
    "   \n",
    "batch_size = 500\n",
    "\n",
    "netG = _netG_CIFAR10(1, 110).to('cuda')\n",
    "PATH = 'premade/netG_epoch_100.pth'\n",
    "nz= 110\n",
    "num_classes = 10\n",
    "\n",
    "netG.load_state_dict(torch.load(PATH))\n",
    "netG.eval()\n",
    "\n",
    "input = torch.FloatTensor(batch_size, 3,32, 32)\n",
    "noise = torch.FloatTensor(batch_size, nz, 1, 1)\n",
    "eval_noise = torch.FloatTensor(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "dis_label = torch.FloatTensor(batch_size)\n",
    "aux_label = torch.LongTensor(batch_size)\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "eval_noise_ = np.random.normal(0, 1, (batch_size, nz))\n",
    "eval_label = np.random.randint(0, num_classes, batch_size)\n",
    "eval_onehot = np.zeros((batch_size, num_classes))\n",
    "eval_onehot[np.arange(batch_size), eval_label] = 1\n",
    "eval_noise_[np.arange(batch_size), :num_classes] = eval_onehot[np.arange(batch_size)]\n",
    "eval_noise_ = (torch.from_numpy(eval_noise_))\n",
    "eval_noise.data.copy_(eval_noise_.view(batch_size, nz, 1, 1))\n",
    "\n",
    "noise.data.resize_(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "label = np.random.randint(0, num_classes, batch_size)\n",
    "noise_ = np.random.normal(0, 1, (batch_size, nz))\n",
    "class_onehot = np.zeros((batch_size, num_classes))\n",
    "class_onehot[np.arange(batch_size), label] = 1\n",
    "noise_[np.arange(batch_size), :num_classes] = class_onehot[np.arange(batch_size)]\n",
    "noise_ = (torch.from_numpy(noise_))\n",
    "noise.data.copy_(noise_.view(batch_size, nz, 1, 1))\n",
    "aux_label.data.resize_(batch_size).copy_(torch.from_numpy(label))\n",
    "noise = noise.to(\"cuda\")\n",
    "fake = netG(noise)\n",
    "\n",
    "iss = inception_score(fake,resize = True)\n",
    "print(iss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9759814052685813 0.0002860229374768393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/5907paper/msssim.py:172: RuntimeWarning: invalid value encountered in power\n",
      "  return (np.prod(mcs[0:levels-1] ** weights[0:levels-1]) *\n",
      "/home/jovyan/work/5907paper/msssim.py:173: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  (mssim[levels-1] ** weights[levels-1]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6388277528071316 0.06139795373997667\n",
      "0.595976417319075 0.05681847116750847\n",
      "0.5961661314803359 0.059277975068045115\n",
      "0.6051750304621626 0.05680380883212092\n",
      "0.5851483882665158 0.061651454372759006\n",
      "0.5867779518003859 0.05004555419271459\n",
      "0.5827149470800661 0.05952185603112699\n",
      "0.5934325529576886 0.05880507057072949\n",
      "0.6001077277801714 0.06569094071497811\n",
      "0.5880500863399958 0.06034135064267417\n"
     ]
    }
   ],
   "source": [
    "avgmsssims = []\n",
    "for epoch in range(0,550,50):\n",
    "    epoch = str(epoch)\n",
    "    net_g = oldNetG(110).to('cuda')\n",
    "    PATH = 'original_model/models/netG_epoch_'+epoch+'.pth'\n",
    "\n",
    "    net_g.load_state_dict(torch.load(PATH))\n",
    "    net_g.eval()\n",
    "    \n",
    "    model_msssims = []\n",
    "    for j in range(10):\n",
    "        batch_size = 200\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        np_gen_label = np.ones(batch_size)*j\n",
    "        onehot = np.zeros((batch_size, 10))\n",
    "        onehot[np.arange(batch_size), np_gen_label.astype('int')] = 1\n",
    "        z = np.concatenate((noise, onehot), axis=1)\n",
    "        z = torch.from_numpy(z).float().to('cuda')\n",
    "\n",
    "\n",
    "        gen_imgs = net_g(z)\n",
    "        gen_imgs = torch.clamp(gen_imgs, -1,1)\n",
    "\n",
    "        gen_imgs = torch.unsqueeze(gen_imgs,1)\n",
    "\n",
    "        ims = [i.cpu().detach().numpy() for i in gen_imgs]\n",
    "\n",
    "        msssims = []\n",
    "        for i in range(100):\n",
    "            msssim = MultiScaleSSIM(ims[int(i*2)], ims[int(i*2)+1], 2)\n",
    "            if msssim <1 and msssim>0:\n",
    "                msssims.append(msssim)\n",
    "        avg = np.average(msssims)\n",
    "        model_msssims.append(avg)\n",
    "    avgmsssims.append(model_msssims)\n",
    "    print(np.average(model_msssims), np.std(model_msssims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9857179210336777 0.0002565075509477855\n",
      "0.7882750255767357 0.06186495478357706\n",
      "0.7994986122045458 0.05468561743246797\n",
      "0.7938468413019109 0.07985497094817709\n",
      "0.7863713294244428 0.07403534739045659\n",
      "0.7784688819813901 0.058945102195056526\n",
      "0.8058418902480018 0.06865579647816059\n",
      "0.8030375860621118 0.07923368814750369\n",
      "0.8223005283471216 0.08579992006643335\n",
      "0.8028884247690687 0.08011746228864343\n",
      "0.7856904546235237 0.05294809416163964\n"
     ]
    }
   ],
   "source": [
    "avgmsssims = []\n",
    "for epoch in range(0,550,50):\n",
    "    epoch = str(epoch)\n",
    "    net_g = newNetG(110).to('cuda')\n",
    "    PATH = 'new_model/models/netG_epoch_'+epoch+'.pth'\n",
    "\n",
    "    net_g.load_state_dict(torch.load(PATH))\n",
    "    net_g.eval()\n",
    "\n",
    "    model_msssims = []\n",
    "    for j in range(10):\n",
    "        batch_size = 200\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        np_gen_label = np.ones(batch_size)*j\n",
    "        onehot = np.zeros((batch_size, 10))\n",
    "        onehot[np.arange(batch_size), np_gen_label.astype('int')] = 1\n",
    "        z = np.concatenate((noise, onehot), axis=1)\n",
    "        z = torch.from_numpy(z).float().to('cuda')\n",
    "\n",
    "\n",
    "        gen_imgs = net_g(z)\n",
    "        gen_imgs = torch.clamp(gen_imgs, -1,1)\n",
    "\n",
    "        gen_imgs = torch.unsqueeze(gen_imgs,1)\n",
    "\n",
    "        ims = [i.cpu().detach().numpy() for i in gen_imgs]\n",
    "\n",
    "        msssims = []\n",
    "        for i in range(100):\n",
    "            msssim = MultiScaleSSIM(ims[int(i*2)], ims[int(i*2)+1], 2)\n",
    "            if msssim <1 and msssim>0:\n",
    "                msssims.append(msssim)\n",
    "        avg = np.average(msssims)\n",
    "        model_msssims.append(avg)\n",
    "    avgmsssims.append(model_msssims)\n",
    "    print(np.average(model_msssims), np.std(model_msssims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
